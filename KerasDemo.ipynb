{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Tell theano to use our GPU\n",
    "os.environ['THEANO_FLAGS'] = \"device=gpu0\"\n",
    "\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Some intro stuff here maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs\n",
    "\n",
    "Note: This slightly follows lesson 1 from [course.fast.ai](http://course.fast.ai/lessons/lesson1.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use Keras to participate in the [Dogs vs Cats Redux Kaggle competition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition) while exploring Keras along the way.\n",
    "\n",
    "\n",
    "\n",
    "The goal of this competition is to predict whether a given image is of a cat or a dog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data\n",
    "\n",
    "[Kaggle gives us](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) two folders: train and test.\n",
    "\n",
    "* The train folder is comprised of 12,500 cats and 12,500 dogs. These cat images are labelled cat.0.jpg through cat.12499.jpg. The opposite is true for dogs.\n",
    "\n",
    "* The test folder has 12,500 unlabelled images.\n",
    "\n",
    "\n",
    "We will start by creating our testing, training, and validation set. We will use 30% of the training images for validation.\n",
    "\n",
    "I will assume our train folder is located at _data/train_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of the train / test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats:\n",
      " ['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.1000.jpg', 'cat.10000.jpg', 'cat.10001.jpg', 'cat.10002.jpg', 'cat.10003.jpg', 'cat.10004.jpg'] \n",
      "Amount:\n",
      " 12500\n",
      "Dogs:\n",
      " ['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.1000.jpg', 'dog.10000.jpg', 'dog.10001.jpg', 'dog.10002.jpg', 'dog.10003.jpg', 'dog.10004.jpg'] \n",
      "Amount:\n",
      " 12500\n",
      "8750 3750 12500\n",
      "8750 3750 12500\n"
     ]
    }
   ],
   "source": [
    "# Since we have no validation set, we need to split our existing training set into train/valid\n",
    "# We will use this amount of the old training set for our new training set. The rest will be for valid.\n",
    "percent_train = 0.7 \n",
    "path = 'data'\n",
    "\n",
    "train_path = path + '/train'\n",
    "valid_path  = path + '/valid'\n",
    "\n",
    "# Get all of the files in the directory\n",
    "train_files = os.listdir(train_path)\n",
    "\n",
    "# Make a list of only the cats and dogs\n",
    "cats = [s for s in train_files if s[:3] == 'cat']\n",
    "dogs = [s for s in train_files if s[:3] == 'dog']\n",
    "\n",
    "# Sanity Check\n",
    "print('Cats:\\n', cats[:10], '\\nAmount:\\n', len(cats))\n",
    "print('Dogs:\\n', dogs[:10], '\\nAmount:\\n', len(dogs))\n",
    "\n",
    "train_cat_amt = int(percent_train * len(cats))\n",
    "train_dog_amt = int(percent_train * len(dogs))\n",
    "\n",
    "cats_train = cats[:train_cat_amt]\n",
    "cats_valid = cats[train_cat_amt:]\n",
    "\n",
    "dogs_train = dogs[:train_dog_amt]\n",
    "dogs_valid = dogs[train_dog_amt:]\n",
    "\n",
    "print(len(cats_train),len(cats_valid),len(cats))\n",
    "print(len(dogs_train),len(dogs_valid),len(dogs))\n",
    "\n",
    "# Make sure we didn't lose any from an index error\n",
    "assert len(cats_train) + len(cats_valid) == len(cats)\n",
    "assert len(dogs_train) + len(dogs_valid) == len(dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all of the cats in a cat folder and all of the dogs in a dog folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make Folders to put them in if they don't exist\n",
    "def make_dir_if_needed(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "make_dir_if_needed(train_path + '/cats')\n",
    "make_dir_if_needed(train_path + '/dogs')\n",
    "\n",
    "make_dir_if_needed(valid_path)\n",
    "make_dir_if_needed(valid_path + '/cats')\n",
    "make_dir_if_needed(valid_path + '/dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import move\n",
    "\n",
    "'''TRAIN'''\n",
    "\n",
    "# Move the cats to the cat directory\n",
    "for cat in cats_train:\n",
    "    move(train_path + '/' + cat, train_path + '/cats/' + cat)\n",
    "\n",
    "# Move the dogs to the dog directory\n",
    "for dog in dogs_train:\n",
    "    move(train_path + '/' + dog, train_path + '/dogs/' + dog)\n",
    "    \n",
    "    \n",
    "'''VALID'''\n",
    "\n",
    "for cat in cats_valid:\n",
    "    move(train_path + '/' + cat, valid_path + '/cats/' + cat)\n",
    "    \n",
    "    \n",
    "for dog in dogs_valid:\n",
    "    move(train_path + '/' + dog, valid_path + '/dogs/' + dog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all of our cats in cat folders and all our dogs in dog folders. We also made our training, testing, and validation set on the filesystem.\n",
    "\n",
    "Here is the current structure of our directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata\\n    test\\n    train\\n        cats\\n        dogs\\n    valid\\n        cats\\n        dogs\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data\n",
    "    test\n",
    "    train\n",
    "        cats\n",
    "        dogs\n",
    "    valid\n",
    "        cats\n",
    "        dogs\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data using Keras\n",
    "\n",
    "Now that we set up our data into a folder for each class, we may now load the data using Keras. This is easily done with an [ImageDataGenerator](https://keras.io/preprocessing/image/#imagedatagenerator). MORE INFO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images belonging to 2 classes.\n",
      "Found 7500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "generator = image.ImageDataGenerator()\n",
    "\n",
    "# Credit: https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py#L142\n",
    "# TODO: Explain this function\n",
    "def get_batches(path, shuffle = True, batch_size = 32, class_mode = 'categorical'):\n",
    "    image.ImageDataGenerator().flow_from_directory(path, target_size = (224, 224), \n",
    "                           class_mode = class_mode, shuffle = shuffle, batch_size = batch_size)\n",
    "\n",
    "train_batches = get_batches(train_path)\n",
    "valid_batches = get_batches(valid_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
